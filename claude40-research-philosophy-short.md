# Research Philosophy Guide

## Our Core Commitments
1. **Truth-seeking over rhetoric** - We prioritise accuracy over persuasion
2. **Epistemic humility** - We acknowledge limitations transparently
3. **Steel-manning opposition** - We present opposing views at their strongest
4. **Evidence-based claims** - We calibrate claims to evidence strength
5. **Radical transparency** - We make our work maximally open and reproducible

## Theoretical Framework
- **Epistemology**: Pragmatic empiricism - evidence-based but aware of its limits
- **Archaeology**: Cognitive-processualism - systemic change with human agency
- **History**: Annales School - *longue durÃ©e* perspective
- **Innovation**: New methods are research, not just tools

## How We Implement Our Principles

### Truth-seeking
- Frame research around specific questions (not just "exploring")
- Ground all conclusions directly in evidence
- Report failures and negative results openly
- Document null evidence as rigorously as positive findings
- Examples: Counter-intuitive mound patterns ("Ordered Logit Model"); ML failures ("Validating ML Predictions")

### Epistemic Humility
- Use cautious language: "suggests," "indicates," "appears to"
- Acknowledge data limitations upfront (sample size, preservation bias)
- Frame preliminary findings appropriately ("potential," "promising")
- Example: "glimpse of undeveloped proto-Panhellenism" ("Barbarophonos")

### Steel-manning
- Engage the full spectrum of existing scholarship
- Present strongest version of counter-arguments before critique
- When findings contradict expectations, explore why openly
- Example: Comparing crowdsourcing vs desktop GIS/ML fairly ("Creating Geospatial Datasets")

### Evidence Standards
- Multiple independent lines of evidence where possible
- Systematic, documented data collection protocols
- Validate methods against ground truth
- Quantitative analysis where appropriate
- Example: Pollen + charcoal + magnetics ("Straldzha Mire")

### Claim Calibration
- Strong claims need strong evidence
- Distinguish exploratory from confirmatory research
- Use preregistration for hypothesis-testing
- Link every claim explicitly to supporting evidence
- Example: Field validation tempering ML conclusions ("Validating ML Predictions")

### Transparency
- Document methods for replication
- Share data, code, and "failed" attempts
- Make outputs FAIR by design
- Acknowledge all contributions generously
- Example: GitHub repositories, open FAIMS development

## Research Practice

### Method Selection
- Choose pragmatically based on question and context
- Prioritise comparability (80% ideal + compatible > 100% isolated)
- Innovate within frameworks that maintain compatibility
- Cost-benefit thinking over methodological dogma

### Research Integrity
- Document data handling at every stage
- Report all significant outcomes (including negative)
- Maintain version control and decision logs
- Enable reproducibility through detailed documentation

### Ethical Standards
- Respect heritage and data sovereignty
- Support local priorities and capacity building
- Apply FAIR principles ethically ("as open as possible, as closed as necessary")
- Generous co-authorship and acknowledgment

## Cognitive Biases We Guard Against
- **Confirmation bias** - seeking supporting evidence
- **Survivorship bias** - overlooking what didn't preserve
- **Anchoring bias** - over-weighting first information
- **Hindsight bias** - seeing patterns as inevitable

## Quick Reminders
- Problem-oriented > method-oriented research
- Compatibility > perfection in methods
- Document failures as learning opportunities
- Preregister confirmatory research
- Share everything (ethically)
- Calibrate language to evidence
- Steel-man before you critique